# ğŸ”§ Modular Deep Learning Pipeline with PyTorch

This repository provides a modular, extensible deep learning pipeline built with PyTorch. It supports multiple model architecturesâ€”including **MLPs**, **CNNs**, **RNNs**, **LSTMs**, and **Transformers**â€”defined through high-level configuration specs. The framework allows for easy training, evaluation, and future deployment, with a focus on clarity, scalability, and customization.

---

## ğŸš€ Features

- âœ… High-level model configuration using JSON files
- âœ… Modular support for CNNs, RNNs, LSTMs, MLPs, and Transformers
- âœ… Custom weight initialization (Xavier, Kaiming)
- âœ… Custom loss and optimizer factory modules
- âœ… Training and evaluation pipeline with AMP support
- âœ… Accuracy and regression metric evaluation
- âœ… Matplotlib-based plotting for training curves
- âœ… Flexible dataset setup supporting all torchvision datasets

---

## ğŸ“ Project Structure

\`\`\`bash
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ rnn_config.json
â”‚   â”‚   â”œâ”€â”€ mlp_config.json
â”‚   â”‚   â”œâ”€â”€ transformer_config.json
â”‚   â”‚   â”œâ”€â”€ lstm_config.json
â”‚   â”‚   â””â”€â”€ cnn_config.json
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ train_config.json
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ dataset_config.json
â”œâ”€â”€ data/ # Dataset storage
â”œâ”€â”€ loss_factory/
â”œâ”€â”€ model_factory/
â”œâ”€â”€ optim_factory/
â”œâ”€â”€ config.py
â”œâ”€â”€ data.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ train.py
â””â”€â”€ main.py
\`\`\`

---

## ğŸ§ª Example Usage: CIFAR-10 CNN

You can train a CNN on CIFAR-10 simply by running:

\`\`\`bash
python main.py
\`\`\`

### ğŸ”§ \`dataset_config.json\` Format

The \`dataset_config.json\` supports both **torchvision sample datasets** and **custom datasets**.

#### âœ… For Torchvision Datasets (e.g. CIFAR-10):

\`\`\`json
{
  "type": "torchvision",
  "name": "CIFAR10",
  "train": true,
  "download": true,
  "normalize_mean": [0.5, 0.5, 0.5],
  "normalize_std": [0.5, 0.5, 0.5]
}
\`\`\`

#### âœ… For Custom Datasets (CSV/NPY/Images):

\`\`\`json
{
  "type": "custom",
  "name": "path/to/your/data",
  "format": "csv",
  "label_column": "target",
  "normalize_mean": [0.0],
  "normalize_std": [1.0]
}
\`\`\`

> Only datasets with both \`normalize_mean\` and \`normalize_std\` will be normalized. Omit these keys to skip normalization.

---

## ğŸ—ï¸ Building and Training the Model

Key steps from \`main.py\`:
\`\`\`python
# Load configs
with open('configs/data/dataset_config.json') as f:
    dataset_config = json.load(f)

# Auto-select torchvision datasets via type field
if dataset_config["type"] == "torchvision":
    dataset_cls = get_torchvision_dataset(dataset_config["name"])
    transform = build_transform(dataset_config)  # builds Normalize only if fields exist
    train_dataset = dataset_cls(root="data", train=True, download=dataset_config.get("download", True), transform=transform)
    test_dataset = dataset_cls(root="data", train=False, download=dataset_config.get("download", True), transform=transform)
else:
    # Handle custom dataset logic here
    X, y = load_custom_dataset(dataset_config)
    train_dataset = Data(X["train"], y["train"], device)
    test_dataset = Data(X["test"], y["test"], device)

# Create loaders
train_loader = get_dataloader(train_dataset, batch_size=train_config["batch_size"], shuffle=train_config["shuffle"])
test_loader = get_dataloader(test_dataset, batch_size=train_config["batch_size"])
\`\`\`

---

## ğŸ”® Future Work

- âš™ï¸ Prefect Pipeline Orchestration
- ğŸ“ˆ MLflow Experiment Tracking and Deployment

---

## ğŸ“¦ Requirements

\`\`\`bash
pip install -r requirements.txt
\`\`\`

**Dependencies** include:
- Python 3.8+
- PyTorch
- torchvision
- matplotlib
- scikit-learn

---

## ğŸ¤ Contributing

Pull requests welcome! The modular layout is ideal for research prototyping and open-source collaboration.
